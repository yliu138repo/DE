{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Aggr tutorial\").getOrCreate()\n",
    "df = spark.createDataFrame([(1, 10.0),\n",
    "                            (2, float(\"nan\")),\n",
    "                            (3, 20.0),\n",
    "                            (4, float(\"nan\")),\n",
    "                            (5, 10.0),\n",
    "                            (6, float(\"nan\")),\n",
    "                            (7, 20.0),\n",
    "                            (8, float(\"nan\")),\n",
    "                            (9, 10.0),\n",
    "                            (10, float(\"nan\")),\n",
    "                            ]\n",
    "                           ,\n",
    "                           [\"Id\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| Id|Value|\n",
      "+---+-----+\n",
      "|  1| 10.0|\n",
      "|  2|  NaN|\n",
      "|  3| 20.0|\n",
      "|  4|  NaN|\n",
      "|  5| 10.0|\n",
      "|  6|  NaN|\n",
      "|  7| 20.0|\n",
      "|  8|  NaN|\n",
      "|  9| 10.0|\n",
      "| 10|  NaN|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "| Id|Value|Value_mean|\n",
      "+---+-----+----------+\n",
      "|  1| 10.0|      10.0|\n",
      "|  2|  NaN|      14.0|\n",
      "|  3| 20.0|      20.0|\n",
      "|  4|  NaN|      14.0|\n",
      "|  5| 10.0|      10.0|\n",
      "|  6|  NaN|      14.0|\n",
      "|  7| 20.0|      20.0|\n",
      "|  8|  NaN|      14.0|\n",
      "|  9| 10.0|      10.0|\n",
      "| 10|  NaN|      14.0|\n",
      "+---+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "\n",
    "input_cols=['Value']\n",
    "output_cols_mean=[\"Value_mean\"]\n",
    "\n",
    "\n",
    "i_mean = Imputer(strategy='mean', inputCols=input_cols, outputCols=output_cols_mean)\n",
    "\n",
    "\n",
    "imputer_model_mean = i_mean.fit(df)\n",
    "\n",
    "\n",
    "imputed_df=imputer_model_mean.transform(df)\n",
    "imputed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "| Id|Value|Value_mean|\n",
      "+---+-----+----------+\n",
      "|  1| 10.0|      10.0|\n",
      "|  2|  NaN|      14.0|\n",
      "|  3| 20.0|      20.0|\n",
      "|  4|  NaN|      14.0|\n",
      "|  5| 10.0|      10.0|\n",
      "|  6|  NaN|      14.0|\n",
      "|  7| 20.0|      20.0|\n",
      "|  8|  NaN|      14.0|\n",
      "|  9| 10.0|      10.0|\n",
      "| 10|  NaN|      14.0|\n",
      "+---+-----+----------+\n",
      "\n",
      "+---+-----+----------+------------+----------+\n",
      "| Id|Value|Value_mean|Value_median|Value_mode|\n",
      "+---+-----+----------+------------+----------+\n",
      "|  1| 10.0|      10.0|        10.0|      10.0|\n",
      "|  2|  NaN|      14.0|        10.0|      10.0|\n",
      "|  3| 20.0|      20.0|        20.0|      20.0|\n",
      "|  4|  NaN|      14.0|        10.0|      10.0|\n",
      "|  5| 10.0|      10.0|        10.0|      10.0|\n",
      "|  6|  NaN|      14.0|        10.0|      10.0|\n",
      "|  7| 20.0|      20.0|        20.0|      20.0|\n",
      "|  8|  NaN|      14.0|        10.0|      10.0|\n",
      "|  9| 10.0|      10.0|        10.0|      10.0|\n",
      "| 10|  NaN|      14.0|        10.0|      10.0|\n",
      "+---+-----+----------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "input_cols=['Value']\n",
    "output_cols_mean=[\"Value_mean\"]\n",
    "output_cols_median=[\"Value_median\"]\n",
    "output_cols_mode=[\"Value_mode\"]\n",
    "\n",
    "i_mean = Imputer(strategy='mean', inputCols=input_cols, outputCols=output_cols_mean)\n",
    "i_median = Imputer(strategy='median', inputCols=input_cols, outputCols=output_cols_median)\n",
    "i_mode = Imputer(strategy='mode', inputCols=input_cols, outputCols=output_cols_mode)\n",
    "\n",
    "\n",
    "imputer_model_mean = i_mean.fit(df)\n",
    "imputer_model_median = i_median.fit(df)\n",
    "imputer_model_mode = i_mode.fit(df)\n",
    "\n",
    "imputed_df=imputer_model_mean.transform(df)\n",
    "imputed_df.show()\n",
    "imputed_df=imputer_model_median.transform(imputed_df)\n",
    "# imputed_df.show()\n",
    "imputed_df=imputer_model_mode.transform(imputed_df)\n",
    "imputed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
